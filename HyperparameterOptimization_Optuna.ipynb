{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60b1e71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/envs/python38/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from hyperopt import hp,fmin,tpe,STATUS_OK,Trials\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1989bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/Preprocessed_data_with_date/airplane_train_processed_date.csv')\n",
    "df_val = pd.read_csv('../data/Preprocessed_data_with_date/airplane_test_processed_date.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9058ace5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((102825, 24), (25976, 24), (102825,), (25976,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['Gender_Female', 'Customer Type_Loyal Customer',\n",
    "       'Type of Travel_Business travel',\n",
    "       'Type of Travel_Personal Travel', 'Class_Business',\n",
    "       'Class_Eco', 'Age',\n",
    "       'Flight Distance', 'Departure Delay in Minutes',\n",
    "       'Arrival Delay in Minutes', 'Inflight wifi service',\n",
    "       'Departure/Arrival time convenient',\n",
    "       'Ease of Online booking', 'Gate location',\n",
    "       'Food and drink', 'Online boarding',\n",
    "       'Seat comfort', 'Inflight entertainment',\n",
    "       'On-board service', 'Leg room service',\n",
    "       'Baggage handling', 'Checkin service',\n",
    "       'Inflight service', 'Cleanliness']\n",
    "\n",
    "le = LabelEncoder()\n",
    "X_train = df_train[features]\n",
    "y_train = df_train['satisfaction']\n",
    "y_train = le.fit_transform(y_train)\n",
    "\n",
    "X_val = df_val[features]\n",
    "y_val = df_val['satisfaction']\n",
    "y_val = le.fit_transform(y_val)\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41d91d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial,data=X_train,target=y_train):\n",
    "    \n",
    "    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.3,random_state=15)\n",
    "    param = {\n",
    "        #'tree_method':'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.012,0.016,0.02]),\n",
    "        'n_estimators': 1000, #as original model\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [5,10,15,20,25,30,37,40]),\n",
    "        'random_state': 15,\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "    }\n",
    "    model = xgb.XGBClassifier(**param)  \n",
    "    \n",
    "    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=100,verbose=False)\n",
    "    \n",
    "    preds = model.predict(test_x)\n",
    "    \n",
    "    mse = mean_squared_error(test_y, preds,squared=True)\n",
    "    \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db7d8650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 22:15:02,020]\u001b[0m A new study created in memory with name: no-name-9611f305-d09c-46da-b618-024611f3e54c\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:15:02] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 22:17:28,580]\u001b[0m Trial 0 finished with value: 0.045545902489626554 and parameters: {'lambda': 0.011841232198339177, 'alpha': 0.02608989662963063, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.02, 'max_depth': 25, 'min_child_weight': 100}. Best is trial 0 with value: 0.045545902489626554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:17:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 22:19:28,238]\u001b[0m Trial 1 finished with value: 0.05384465767634855 and parameters: {'lambda': 0.007214749321128512, 'alpha': 0.9018630821941501, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.016, 'max_depth': 15, 'min_child_weight': 168}. Best is trial 0 with value: 0.045545902489626554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:19:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 22:22:40,554]\u001b[0m Trial 2 finished with value: 0.04813926348547718 and parameters: {'lambda': 8.73768225889109, 'alpha': 3.3669218307330238, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.012, 'max_depth': 37, 'min_child_weight': 102}. Best is trial 0 with value: 0.045545902489626554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:22:40] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 22:25:14,323]\u001b[0m Trial 3 finished with value: 0.046939834024896265 and parameters: {'lambda': 0.1635425441629915, 'alpha': 5.013256634459744, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.016, 'max_depth': 20, 'min_child_weight': 102}. Best is trial 0 with value: 0.045545902489626554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:25:14] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 22:26:26,148]\u001b[0m Trial 4 finished with value: 0.06629279045643154 and parameters: {'lambda': 0.3682497514820749, 'alpha': 0.03394106215383994, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.008, 'max_depth': 10, 'min_child_weight': 196}. Best is trial 0 with value: 0.045545902489626554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:26:26] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 22:27:56,343]\u001b[0m Trial 5 finished with value: 0.06382909751037344 and parameters: {'lambda': 0.5349857474487847, 'alpha': 0.010305271197789363, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 25, 'min_child_weight': 195}. Best is trial 0 with value: 0.045545902489626554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:27:56] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 22:28:58,486]\u001b[0m Trial 6 finished with value: 0.07089600622406639 and parameters: {'lambda': 0.011745536546949112, 'alpha': 0.14047155920731055, 'colsample_bytree': 0.6, 'subsample': 0.4, 'learning_rate': 0.008, 'max_depth': 40, 'min_child_weight': 178}. Best is trial 0 with value: 0.045545902489626554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:28:58] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 22:30:10,436]\u001b[0m Trial 7 finished with value: 0.06989107883817428 and parameters: {'lambda': 0.3293504301787546, 'alpha': 0.10238189613777077, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 5, 'min_child_weight': 248}. Best is trial 0 with value: 0.045545902489626554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:30:10] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 22:31:32,797]\u001b[0m Trial 8 finished with value: 0.06557961618257262 and parameters: {'lambda': 3.400331364636343, 'alpha': 0.0072777696019689945, 'colsample_bytree': 0.5, 'subsample': 0.6, 'learning_rate': 0.016, 'max_depth': 25, 'min_child_weight': 277}. Best is trial 0 with value: 0.045545902489626554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:31:33] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 22:32:58,362]\u001b[0m Trial 9 finished with value: 0.06697354771784232 and parameters: {'lambda': 4.479323810073782, 'alpha': 0.35506676834326445, 'colsample_bytree': 0.8, 'subsample': 0.4, 'learning_rate': 0.012, 'max_depth': 40, 'min_child_weight': 180}. Best is trial 0 with value: 0.045545902489626554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:32:58] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 22:35:23,973]\u001b[0m Trial 10 finished with value: 0.04126685684647303 and parameters: {'lambda': 0.0012415947786318126, 'alpha': 0.0017034782532461131, 'colsample_bytree': 0.5, 'subsample': 0.5, 'learning_rate': 0.02, 'max_depth': 30, 'min_child_weight': 5}. Best is trial 10 with value: 0.04126685684647303.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:35:24] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 22:37:42,574]\u001b[0m Trial 11 finished with value: 0.04152619294605809 and parameters: {'lambda': 0.0010274900980701673, 'alpha': 0.0011964765166066482, 'colsample_bytree': 0.5, 'subsample': 0.5, 'learning_rate': 0.02, 'max_depth': 30, 'min_child_weight': 9}. Best is trial 10 with value: 0.04126685684647303.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:42] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 22:41:18,706]\u001b[0m Trial 12 finished with value: 0.04149377593360996 and parameters: {'lambda': 0.0010588191533163964, 'alpha': 0.0010277148761680898, 'colsample_bytree': 0.5, 'subsample': 0.5, 'learning_rate': 0.02, 'max_depth': 30, 'min_child_weight': 1}. Best is trial 10 with value: 0.04126685684647303.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:41:19] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 22:43:58,673]\u001b[0m Trial 13 finished with value: 0.04220695020746888 and parameters: {'lambda': 0.0011118057087605138, 'alpha': 0.0010636116951808548, 'colsample_bytree': 0.5, 'subsample': 0.5, 'learning_rate': 0.02, 'max_depth': 30, 'min_child_weight': 12}. Best is trial 10 with value: 0.04126685684647303.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:43:59] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 22:46:53,890]\u001b[0m Trial 14 finished with value: 0.04603215767634855 and parameters: {'lambda': 0.0034481933953811384, 'alpha': 0.0030204673018620343, 'colsample_bytree': 0.5, 'subsample': 0.5, 'learning_rate': 0.02, 'max_depth': 30, 'min_child_weight': 47}. Best is trial 10 with value: 0.04126685684647303.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:46:54] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 22:50:09,055]\u001b[0m Trial 15 finished with value: 0.04431405601659751 and parameters: {'lambda': 0.026652571081849128, 'alpha': 0.0035891763313389783, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 30, 'min_child_weight': 51}. Best is trial 10 with value: 0.04126685684647303.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:50:09] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 22:52:30,463]\u001b[0m Trial 16 finished with value: 0.04723158713692946 and parameters: {'lambda': 0.0026202635492148115, 'alpha': 0.0010098833817686749, 'colsample_bytree': 0.9, 'subsample': 0.5, 'learning_rate': 0.02, 'max_depth': 30, 'min_child_weight': 66}. Best is trial 10 with value: 0.04126685684647303.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:52:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 22:56:36,633]\u001b[0m Trial 17 finished with value: 0.0409426867219917 and parameters: {'lambda': 0.035090977802052566, 'alpha': 0.004031598747017301, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.02, 'max_depth': 15, 'min_child_weight': 3}. Best is trial 17 with value: 0.0409426867219917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:56:37] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 22:59:18,019]\u001b[0m Trial 18 finished with value: 0.04911177385892116 and parameters: {'lambda': 0.04469538406907935, 'alpha': 0.013460059655596674, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 15, 'min_child_weight': 136}. Best is trial 17 with value: 0.0409426867219917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:59:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 23:02:27,470]\u001b[0m Trial 19 finished with value: 0.04629149377593361 and parameters: {'lambda': 0.04512239216258642, 'alpha': 0.0036961381392825697, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 15, 'min_child_weight': 38}. Best is trial 17 with value: 0.0409426867219917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:02:27] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 23:03:38,454]\u001b[0m Trial 20 finished with value: 0.050765041493775934 and parameters: {'lambda': 0.004143685016439402, 'alpha': 0.031561211743647476, 'colsample_bytree': 0.7, 'subsample': 0.5, 'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 76}. Best is trial 17 with value: 0.0409426867219917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:03:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 23:06:30,802]\u001b[0m Trial 21 finished with value: 0.04155860995850622 and parameters: {'lambda': 0.00186759099211555, 'alpha': 0.0024142840484578385, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.02, 'max_depth': 37, 'min_child_weight': 1}. Best is trial 17 with value: 0.0409426867219917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:06:31] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 23:08:39,447]\u001b[0m Trial 22 finished with value: 0.04424922199170125 and parameters: {'lambda': 0.0062457212761915775, 'alpha': 0.005373925448864852, 'colsample_bytree': 0.5, 'subsample': 0.5, 'learning_rate': 0.02, 'max_depth': 20, 'min_child_weight': 29}. Best is trial 17 with value: 0.0409426867219917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:08:39] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 23:10:26,540]\u001b[0m Trial 23 finished with value: 0.04350363070539419 and parameters: {'lambda': 0.001388288688818988, 'alpha': 0.0017574537866965946, 'colsample_bytree': 0.5, 'subsample': 0.5, 'learning_rate': 0.02, 'max_depth': 10, 'min_child_weight': 22}. Best is trial 17 with value: 0.0409426867219917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:10:26] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 23:12:31,114]\u001b[0m Trial 24 finished with value: 0.04836618257261411 and parameters: {'lambda': 0.002126094867292863, 'alpha': 0.0028038262545018056, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.02, 'max_depth': 15, 'min_child_weight': 79}. Best is trial 17 with value: 0.0409426867219917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:12:31] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 23:14:08,302]\u001b[0m Trial 25 finished with value: 0.054752334024896265 and parameters: {'lambda': 0.0037718350825321984, 'alpha': 0.0061738163446236555, 'colsample_bytree': 0.5, 'subsample': 0.5, 'learning_rate': 0.02, 'max_depth': 30, 'min_child_weight': 131}. Best is trial 17 with value: 0.0409426867219917.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:14:08] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 23:16:30,236]\u001b[0m Trial 26 finished with value: 0.040877852697095436 and parameters: {'lambda': 0.013897993486708967, 'alpha': 0.0018108315682244345, 'colsample_bytree': 0.6, 'subsample': 0.4, 'learning_rate': 0.02, 'max_depth': 30, 'min_child_weight': 2}. Best is trial 26 with value: 0.040877852697095436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:16:30] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 23:18:07,943]\u001b[0m Trial 27 finished with value: 0.04985736514522822 and parameters: {'lambda': 0.02008463010407016, 'alpha': 0.002083341777684316, 'colsample_bytree': 0.6, 'subsample': 0.4, 'learning_rate': 0.016, 'max_depth': 15, 'min_child_weight': 55}. Best is trial 26 with value: 0.040877852697095436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:18:08] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 23:19:51,894]\u001b[0m Trial 28 finished with value: 0.04635632780082988 and parameters: {'lambda': 0.06291215015520511, 'alpha': 0.013254370121914003, 'colsample_bytree': 0.6, 'subsample': 0.4, 'learning_rate': 0.012, 'max_depth': 30, 'min_child_weight': 33}. Best is trial 26 with value: 0.040877852697095436.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:19:52] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-18 23:21:07,326]\u001b[0m Trial 29 finished with value: 0.05329356846473029 and parameters: {'lambda': 0.010218259985044135, 'alpha': 0.018986291778773066, 'colsample_bytree': 0.6, 'subsample': 0.4, 'learning_rate': 0.02, 'max_depth': 40, 'min_child_weight': 91}. Best is trial 26 with value: 0.040877852697095436.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c426cc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_alpha</th>\n",
       "      <th>params_colsample_bytree</th>\n",
       "      <th>params_lambda</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_min_child_weight</th>\n",
       "      <th>params_subsample</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.045546</td>\n",
       "      <td>2023-04-18 22:15:02.027401</td>\n",
       "      <td>2023-04-18 22:17:28.577840</td>\n",
       "      <td>0 days 00:02:26.550439</td>\n",
       "      <td>0.026090</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.011841</td>\n",
       "      <td>0.020</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.053845</td>\n",
       "      <td>2023-04-18 22:17:28.587321</td>\n",
       "      <td>2023-04-18 22:19:28.229887</td>\n",
       "      <td>0 days 00:01:59.642566</td>\n",
       "      <td>0.901863</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007215</td>\n",
       "      <td>0.016</td>\n",
       "      <td>15</td>\n",
       "      <td>168</td>\n",
       "      <td>0.7</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.048139</td>\n",
       "      <td>2023-04-18 22:19:28.246886</td>\n",
       "      <td>2023-04-18 22:22:40.553759</td>\n",
       "      <td>0 days 00:03:12.306873</td>\n",
       "      <td>3.366922</td>\n",
       "      <td>0.9</td>\n",
       "      <td>8.737682</td>\n",
       "      <td>0.012</td>\n",
       "      <td>37</td>\n",
       "      <td>102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.046940</td>\n",
       "      <td>2023-04-18 22:22:40.559012</td>\n",
       "      <td>2023-04-18 22:25:14.319617</td>\n",
       "      <td>0 days 00:02:33.760605</td>\n",
       "      <td>5.013257</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.163543</td>\n",
       "      <td>0.016</td>\n",
       "      <td>20</td>\n",
       "      <td>102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.066293</td>\n",
       "      <td>2023-04-18 22:25:14.333812</td>\n",
       "      <td>2023-04-18 22:26:26.147660</td>\n",
       "      <td>0 days 00:01:11.813848</td>\n",
       "      <td>0.033941</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.368250</td>\n",
       "      <td>0.008</td>\n",
       "      <td>10</td>\n",
       "      <td>196</td>\n",
       "      <td>0.6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.063829</td>\n",
       "      <td>2023-04-18 22:26:26.149206</td>\n",
       "      <td>2023-04-18 22:27:56.337313</td>\n",
       "      <td>0 days 00:01:30.188107</td>\n",
       "      <td>0.010305</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.534986</td>\n",
       "      <td>0.008</td>\n",
       "      <td>25</td>\n",
       "      <td>195</td>\n",
       "      <td>0.7</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.070896</td>\n",
       "      <td>2023-04-18 22:27:56.344665</td>\n",
       "      <td>2023-04-18 22:28:58.485312</td>\n",
       "      <td>0 days 00:01:02.140647</td>\n",
       "      <td>0.140472</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.011746</td>\n",
       "      <td>0.008</td>\n",
       "      <td>40</td>\n",
       "      <td>178</td>\n",
       "      <td>0.4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.069891</td>\n",
       "      <td>2023-04-18 22:28:58.494675</td>\n",
       "      <td>2023-04-18 22:30:10.434716</td>\n",
       "      <td>0 days 00:01:11.940041</td>\n",
       "      <td>0.102382</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.329350</td>\n",
       "      <td>0.008</td>\n",
       "      <td>5</td>\n",
       "      <td>248</td>\n",
       "      <td>0.7</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.065580</td>\n",
       "      <td>2023-04-18 22:30:10.444566</td>\n",
       "      <td>2023-04-18 22:31:32.795384</td>\n",
       "      <td>0 days 00:01:22.350818</td>\n",
       "      <td>0.007278</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.400331</td>\n",
       "      <td>0.016</td>\n",
       "      <td>25</td>\n",
       "      <td>277</td>\n",
       "      <td>0.6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.066974</td>\n",
       "      <td>2023-04-18 22:31:32.806865</td>\n",
       "      <td>2023-04-18 22:32:58.361006</td>\n",
       "      <td>0 days 00:01:25.554141</td>\n",
       "      <td>0.355067</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.479324</td>\n",
       "      <td>0.012</td>\n",
       "      <td>40</td>\n",
       "      <td>180</td>\n",
       "      <td>0.4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.041267</td>\n",
       "      <td>2023-04-18 22:32:58.373962</td>\n",
       "      <td>2023-04-18 22:35:23.973109</td>\n",
       "      <td>0 days 00:02:25.599147</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.020</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.041526</td>\n",
       "      <td>2023-04-18 22:35:23.977039</td>\n",
       "      <td>2023-04-18 22:37:42.572806</td>\n",
       "      <td>0 days 00:02:18.595767</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.020</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.041494</td>\n",
       "      <td>2023-04-18 22:37:42.575658</td>\n",
       "      <td>2023-04-18 22:41:18.697897</td>\n",
       "      <td>0 days 00:03:36.122239</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.020</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.042207</td>\n",
       "      <td>2023-04-18 22:41:18.721746</td>\n",
       "      <td>2023-04-18 22:43:58.672955</td>\n",
       "      <td>0 days 00:02:39.951209</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.020</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.046032</td>\n",
       "      <td>2023-04-18 22:43:58.675480</td>\n",
       "      <td>2023-04-18 22:46:53.887937</td>\n",
       "      <td>0 days 00:02:55.212457</td>\n",
       "      <td>0.003020</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.020</td>\n",
       "      <td>30</td>\n",
       "      <td>47</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.044314</td>\n",
       "      <td>2023-04-18 22:46:53.919868</td>\n",
       "      <td>2023-04-18 22:50:09.054475</td>\n",
       "      <td>0 days 00:03:15.134607</td>\n",
       "      <td>0.003589</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.026653</td>\n",
       "      <td>0.020</td>\n",
       "      <td>30</td>\n",
       "      <td>51</td>\n",
       "      <td>0.8</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.047232</td>\n",
       "      <td>2023-04-18 22:50:09.056726</td>\n",
       "      <td>2023-04-18 22:52:30.462165</td>\n",
       "      <td>0 days 00:02:21.405439</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.002620</td>\n",
       "      <td>0.020</td>\n",
       "      <td>30</td>\n",
       "      <td>66</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.040943</td>\n",
       "      <td>2023-04-18 22:52:30.464897</td>\n",
       "      <td>2023-04-18 22:56:36.628217</td>\n",
       "      <td>0 days 00:04:06.163320</td>\n",
       "      <td>0.004032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.035091</td>\n",
       "      <td>0.020</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.049112</td>\n",
       "      <td>2023-04-18 22:56:36.649993</td>\n",
       "      <td>2023-04-18 22:59:18.018838</td>\n",
       "      <td>0 days 00:02:41.368845</td>\n",
       "      <td>0.013460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.044695</td>\n",
       "      <td>0.020</td>\n",
       "      <td>15</td>\n",
       "      <td>136</td>\n",
       "      <td>0.8</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.046291</td>\n",
       "      <td>2023-04-18 22:59:18.023897</td>\n",
       "      <td>2023-04-18 23:02:27.468264</td>\n",
       "      <td>0 days 00:03:09.444367</td>\n",
       "      <td>0.003696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.045122</td>\n",
       "      <td>0.012</td>\n",
       "      <td>15</td>\n",
       "      <td>38</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.050765</td>\n",
       "      <td>2023-04-18 23:02:27.478700</td>\n",
       "      <td>2023-04-18 23:03:38.453436</td>\n",
       "      <td>0 days 00:01:10.974736</td>\n",
       "      <td>0.031561</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.004144</td>\n",
       "      <td>0.020</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.041559</td>\n",
       "      <td>2023-04-18 23:03:38.455240</td>\n",
       "      <td>2023-04-18 23:06:30.801372</td>\n",
       "      <td>0 days 00:02:52.346132</td>\n",
       "      <td>0.002414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001868</td>\n",
       "      <td>0.020</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.044249</td>\n",
       "      <td>2023-04-18 23:06:30.803143</td>\n",
       "      <td>2023-04-18 23:08:39.446900</td>\n",
       "      <td>0 days 00:02:08.643757</td>\n",
       "      <td>0.005374</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.020</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.043504</td>\n",
       "      <td>2023-04-18 23:08:39.448891</td>\n",
       "      <td>2023-04-18 23:10:26.538756</td>\n",
       "      <td>0 days 00:01:47.089865</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.020</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.048366</td>\n",
       "      <td>2023-04-18 23:10:26.542144</td>\n",
       "      <td>2023-04-18 23:12:31.112787</td>\n",
       "      <td>0 days 00:02:04.570643</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.020</td>\n",
       "      <td>15</td>\n",
       "      <td>79</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.054752</td>\n",
       "      <td>2023-04-18 23:12:31.117911</td>\n",
       "      <td>2023-04-18 23:14:08.300821</td>\n",
       "      <td>0 days 00:01:37.182910</td>\n",
       "      <td>0.006174</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.003772</td>\n",
       "      <td>0.020</td>\n",
       "      <td>30</td>\n",
       "      <td>131</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.040878</td>\n",
       "      <td>2023-04-18 23:14:08.310743</td>\n",
       "      <td>2023-04-18 23:16:30.235436</td>\n",
       "      <td>0 days 00:02:21.924693</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.013898</td>\n",
       "      <td>0.020</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.049857</td>\n",
       "      <td>2023-04-18 23:16:30.237325</td>\n",
       "      <td>2023-04-18 23:18:07.940268</td>\n",
       "      <td>0 days 00:01:37.702943</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.020085</td>\n",
       "      <td>0.016</td>\n",
       "      <td>15</td>\n",
       "      <td>55</td>\n",
       "      <td>0.4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.046356</td>\n",
       "      <td>2023-04-18 23:18:07.953281</td>\n",
       "      <td>2023-04-18 23:19:51.893421</td>\n",
       "      <td>0 days 00:01:43.940140</td>\n",
       "      <td>0.013254</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.062912</td>\n",
       "      <td>0.012</td>\n",
       "      <td>30</td>\n",
       "      <td>33</td>\n",
       "      <td>0.4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.053294</td>\n",
       "      <td>2023-04-18 23:19:51.895299</td>\n",
       "      <td>2023-04-18 23:21:07.326092</td>\n",
       "      <td>0 days 00:01:15.430793</td>\n",
       "      <td>0.018986</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.010218</td>\n",
       "      <td>0.020</td>\n",
       "      <td>40</td>\n",
       "      <td>91</td>\n",
       "      <td>0.4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value             datetime_start          datetime_complete  \\\n",
       "0        0  0.045546 2023-04-18 22:15:02.027401 2023-04-18 22:17:28.577840   \n",
       "1        1  0.053845 2023-04-18 22:17:28.587321 2023-04-18 22:19:28.229887   \n",
       "2        2  0.048139 2023-04-18 22:19:28.246886 2023-04-18 22:22:40.553759   \n",
       "3        3  0.046940 2023-04-18 22:22:40.559012 2023-04-18 22:25:14.319617   \n",
       "4        4  0.066293 2023-04-18 22:25:14.333812 2023-04-18 22:26:26.147660   \n",
       "5        5  0.063829 2023-04-18 22:26:26.149206 2023-04-18 22:27:56.337313   \n",
       "6        6  0.070896 2023-04-18 22:27:56.344665 2023-04-18 22:28:58.485312   \n",
       "7        7  0.069891 2023-04-18 22:28:58.494675 2023-04-18 22:30:10.434716   \n",
       "8        8  0.065580 2023-04-18 22:30:10.444566 2023-04-18 22:31:32.795384   \n",
       "9        9  0.066974 2023-04-18 22:31:32.806865 2023-04-18 22:32:58.361006   \n",
       "10      10  0.041267 2023-04-18 22:32:58.373962 2023-04-18 22:35:23.973109   \n",
       "11      11  0.041526 2023-04-18 22:35:23.977039 2023-04-18 22:37:42.572806   \n",
       "12      12  0.041494 2023-04-18 22:37:42.575658 2023-04-18 22:41:18.697897   \n",
       "13      13  0.042207 2023-04-18 22:41:18.721746 2023-04-18 22:43:58.672955   \n",
       "14      14  0.046032 2023-04-18 22:43:58.675480 2023-04-18 22:46:53.887937   \n",
       "15      15  0.044314 2023-04-18 22:46:53.919868 2023-04-18 22:50:09.054475   \n",
       "16      16  0.047232 2023-04-18 22:50:09.056726 2023-04-18 22:52:30.462165   \n",
       "17      17  0.040943 2023-04-18 22:52:30.464897 2023-04-18 22:56:36.628217   \n",
       "18      18  0.049112 2023-04-18 22:56:36.649993 2023-04-18 22:59:18.018838   \n",
       "19      19  0.046291 2023-04-18 22:59:18.023897 2023-04-18 23:02:27.468264   \n",
       "20      20  0.050765 2023-04-18 23:02:27.478700 2023-04-18 23:03:38.453436   \n",
       "21      21  0.041559 2023-04-18 23:03:38.455240 2023-04-18 23:06:30.801372   \n",
       "22      22  0.044249 2023-04-18 23:06:30.803143 2023-04-18 23:08:39.446900   \n",
       "23      23  0.043504 2023-04-18 23:08:39.448891 2023-04-18 23:10:26.538756   \n",
       "24      24  0.048366 2023-04-18 23:10:26.542144 2023-04-18 23:12:31.112787   \n",
       "25      25  0.054752 2023-04-18 23:12:31.117911 2023-04-18 23:14:08.300821   \n",
       "26      26  0.040878 2023-04-18 23:14:08.310743 2023-04-18 23:16:30.235436   \n",
       "27      27  0.049857 2023-04-18 23:16:30.237325 2023-04-18 23:18:07.940268   \n",
       "28      28  0.046356 2023-04-18 23:18:07.953281 2023-04-18 23:19:51.893421   \n",
       "29      29  0.053294 2023-04-18 23:19:51.895299 2023-04-18 23:21:07.326092   \n",
       "\n",
       "                 duration  params_alpha  params_colsample_bytree  \\\n",
       "0  0 days 00:02:26.550439      0.026090                      0.8   \n",
       "1  0 days 00:01:59.642566      0.901863                      1.0   \n",
       "2  0 days 00:03:12.306873      3.366922                      0.9   \n",
       "3  0 days 00:02:33.760605      5.013257                      0.8   \n",
       "4  0 days 00:01:11.813848      0.033941                      0.7   \n",
       "5  0 days 00:01:30.188107      0.010305                      0.8   \n",
       "6  0 days 00:01:02.140647      0.140472                      0.6   \n",
       "7  0 days 00:01:11.940041      0.102382                      0.6   \n",
       "8  0 days 00:01:22.350818      0.007278                      0.5   \n",
       "9  0 days 00:01:25.554141      0.355067                      0.8   \n",
       "10 0 days 00:02:25.599147      0.001703                      0.5   \n",
       "11 0 days 00:02:18.595767      0.001196                      0.5   \n",
       "12 0 days 00:03:36.122239      0.001028                      0.5   \n",
       "13 0 days 00:02:39.951209      0.001064                      0.5   \n",
       "14 0 days 00:02:55.212457      0.003020                      0.5   \n",
       "15 0 days 00:03:15.134607      0.003589                      0.5   \n",
       "16 0 days 00:02:21.405439      0.001010                      0.9   \n",
       "17 0 days 00:04:06.163320      0.004032                      1.0   \n",
       "18 0 days 00:02:41.368845      0.013460                      1.0   \n",
       "19 0 days 00:03:09.444367      0.003696                      1.0   \n",
       "20 0 days 00:01:10.974736      0.031561                      0.7   \n",
       "21 0 days 00:02:52.346132      0.002414                      1.0   \n",
       "22 0 days 00:02:08.643757      0.005374                      0.5   \n",
       "23 0 days 00:01:47.089865      0.001757                      0.5   \n",
       "24 0 days 00:02:04.570643      0.002804                      1.0   \n",
       "25 0 days 00:01:37.182910      0.006174                      0.5   \n",
       "26 0 days 00:02:21.924693      0.001811                      0.6   \n",
       "27 0 days 00:01:37.702943      0.002083                      0.6   \n",
       "28 0 days 00:01:43.940140      0.013254                      0.6   \n",
       "29 0 days 00:01:15.430793      0.018986                      0.6   \n",
       "\n",
       "    params_lambda  params_learning_rate  params_max_depth  \\\n",
       "0        0.011841                 0.020                25   \n",
       "1        0.007215                 0.016                15   \n",
       "2        8.737682                 0.012                37   \n",
       "3        0.163543                 0.016                20   \n",
       "4        0.368250                 0.008                10   \n",
       "5        0.534986                 0.008                25   \n",
       "6        0.011746                 0.008                40   \n",
       "7        0.329350                 0.008                 5   \n",
       "8        3.400331                 0.016                25   \n",
       "9        4.479324                 0.012                40   \n",
       "10       0.001242                 0.020                30   \n",
       "11       0.001027                 0.020                30   \n",
       "12       0.001059                 0.020                30   \n",
       "13       0.001112                 0.020                30   \n",
       "14       0.003448                 0.020                30   \n",
       "15       0.026653                 0.020                30   \n",
       "16       0.002620                 0.020                30   \n",
       "17       0.035091                 0.020                15   \n",
       "18       0.044695                 0.020                15   \n",
       "19       0.045122                 0.012                15   \n",
       "20       0.004144                 0.020                 5   \n",
       "21       0.001868                 0.020                37   \n",
       "22       0.006246                 0.020                20   \n",
       "23       0.001388                 0.020                10   \n",
       "24       0.002126                 0.020                15   \n",
       "25       0.003772                 0.020                30   \n",
       "26       0.013898                 0.020                30   \n",
       "27       0.020085                 0.016                15   \n",
       "28       0.062912                 0.012                30   \n",
       "29       0.010218                 0.020                40   \n",
       "\n",
       "    params_min_child_weight  params_subsample     state  \n",
       "0                       100               1.0  COMPLETE  \n",
       "1                       168               0.7  COMPLETE  \n",
       "2                       102               1.0  COMPLETE  \n",
       "3                       102               1.0  COMPLETE  \n",
       "4                       196               0.6  COMPLETE  \n",
       "5                       195               0.7  COMPLETE  \n",
       "6                       178               0.4  COMPLETE  \n",
       "7                       248               0.7  COMPLETE  \n",
       "8                       277               0.6  COMPLETE  \n",
       "9                       180               0.4  COMPLETE  \n",
       "10                        5               0.5  COMPLETE  \n",
       "11                        9               0.5  COMPLETE  \n",
       "12                        1               0.5  COMPLETE  \n",
       "13                       12               0.5  COMPLETE  \n",
       "14                       47               0.5  COMPLETE  \n",
       "15                       51               0.8  COMPLETE  \n",
       "16                       66               0.5  COMPLETE  \n",
       "17                        3               0.5  COMPLETE  \n",
       "18                      136               0.8  COMPLETE  \n",
       "19                       38               0.5  COMPLETE  \n",
       "20                       76               0.5  COMPLETE  \n",
       "21                        1               0.5  COMPLETE  \n",
       "22                       29               0.5  COMPLETE  \n",
       "23                       22               0.5  COMPLETE  \n",
       "24                       79               0.5  COMPLETE  \n",
       "25                      131               0.5  COMPLETE  \n",
       "26                        2               0.4  COMPLETE  \n",
       "27                       55               0.4  COMPLETE  \n",
       "28                       33               0.4  COMPLETE  \n",
       "29                       91               0.4  COMPLETE  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d53fc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 30\n",
      "Best trial: {'lambda': 0.013897993486708967, 'alpha': 0.0018108315682244345, 'colsample_bytree': 0.6, 'subsample': 0.4, 'learning_rate': 0.02, 'max_depth': 30, 'min_child_weight': 2}\n",
      "Best MSE: 0.040877852697095436\n"
     ]
    }
   ],
   "source": [
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)\n",
    "print('Best MSE:', study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b71d237",
   "metadata": {},
   "source": [
    "{'lambda': 0.0031790320630051537, 'alpha': 0.11407047947985488, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.012, 'max_depth': 20, 'random_state': 2020, 'min_child_weight': 19}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d27a7942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:30:14] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0446181090237142"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = xgb.XGBClassifier(**study.best_trial.params)\n",
    "final_model.fit(X_train, y_train)\n",
    "y_val_pred = final_model.predict(X_val)\n",
    "mean_squared_error(y_val, y_val_pred,squared=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
