{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21b8b801",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization - HyperOpt\n",
    "### Table of Content\n",
    "I. [**Data Preparation**](#i)<br>\n",
    "II. [**HyperOpt**](#ii)<br>\n",
    "<a id = 'top'>\n",
    "\n",
    "Reference: \n",
    "- <a href='https://optuna.readthedocs.io/en/stable/index.html'>Optuna Documentation</a>\n",
    "- <a href='https://www.kaggle.com/code/hamzaghanmi/xgboost-catboost-using-optuna'>XGBoost & Catboost Using Optuna</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "539d47de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/envs/python38/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from hyperopt import hp,fmin,tpe,STATUS_OK,Trials\n",
    "#from sklearn.metrics import accuracy_score, classification_report, f1_score, mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61472a36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aee3be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/Preprocessed_data_with_date/airplane_train_processed_date.csv')\n",
    "df_val = pd.read_csv('../data/Preprocessed_data_with_date/airplane_test_processed_date.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bc2eebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((102825, 24), (25976, 24), (102825,), (25976,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['Gender_Female', 'Customer Type_Loyal Customer',\n",
    "       'Type of Travel_Business travel',\n",
    "       'Type of Travel_Personal Travel', 'Class_Business',\n",
    "       'Class_Eco', 'Age',\n",
    "       'Flight Distance', 'Departure Delay in Minutes',\n",
    "       'Arrival Delay in Minutes', 'Inflight wifi service',\n",
    "       'Departure/Arrival time convenient',\n",
    "       'Ease of Online booking', 'Gate location',\n",
    "       'Food and drink', 'Online boarding',\n",
    "       'Seat comfort', 'Inflight entertainment',\n",
    "       'On-board service', 'Leg room service',\n",
    "       'Baggage handling', 'Checkin service',\n",
    "       'Inflight service', 'Cleanliness']\n",
    "\n",
    "le = LabelEncoder()\n",
    "X_train = df_train[features]\n",
    "y_train = df_train['satisfaction']\n",
    "y_train = le.fit_transform(y_train)\n",
    "\n",
    "X_val = df_val[features]\n",
    "y_val = df_val['satisfaction']\n",
    "y_val = le.fit_transform(y_val)\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a6c2b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial,data=X_train,target=y_train):\n",
    "    \n",
    "    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.3,random_state=15)\n",
    "    param = {\n",
    "        #'tree_method':'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.012,0.016,0.02]),\n",
    "        'n_estimators': 1000, #as original model\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [5,10,15,20,25,30,37,40]),\n",
    "        'random_state': 15,\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "    }\n",
    "    model = xgb.XGBClassifier(**param)  \n",
    "    \n",
    "    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=100,verbose=False)\n",
    "    \n",
    "    preds = model.predict(test_x)\n",
    "    \n",
    "    accuracy = accuracy_score(test_y, preds)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68694edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 14:22:03,340]\u001b[0m A new study created in memory with name: no-name-70696540-136b-477b-a3f9-e2b59f92bd75\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:22:04] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 14:25:16,642]\u001b[0m Trial 0 finished with value: 0.9487487033195021 and parameters: {'lambda': 0.005430671354336585, 'alpha': 0.05047073135177418, 'colsample_bytree': 0.5, 'subsample': 0.7, 'learning_rate': 0.012, 'max_depth': 25, 'min_child_weight': 93}. Best is trial 0 with value: 0.9487487033195021.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:25:17] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 14:26:33,644]\u001b[0m Trial 1 finished with value: 0.9373379149377593 and parameters: {'lambda': 0.03583365124833772, 'alpha': 0.196233005177544, 'colsample_bytree': 0.9, 'subsample': 0.4, 'learning_rate': 0.016, 'max_depth': 15, 'min_child_weight': 166}. Best is trial 0 with value: 0.9487487033195021.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:26:33] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 14:28:46,275]\u001b[0m Trial 2 finished with value: 0.9455070020746889 and parameters: {'lambda': 2.0100144842215593, 'alpha': 0.04228051343481473, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.012, 'max_depth': 37, 'min_child_weight': 200}. Best is trial 0 with value: 0.9487487033195021.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:28:46] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 14:31:58,252]\u001b[0m Trial 3 finished with value: 0.9556535269709544 and parameters: {'lambda': 0.08007361760862627, 'alpha': 0.013738294998239114, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.016, 'max_depth': 15, 'min_child_weight': 58}. Best is trial 3 with value: 0.9556535269709544.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:31:58] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 14:35:01,339]\u001b[0m Trial 4 finished with value: 0.9573392116182573 and parameters: {'lambda': 0.3269773458932101, 'alpha': 0.36035825085585776, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.016, 'max_depth': 30, 'min_child_weight': 40}. Best is trial 4 with value: 0.9573392116182573.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:35:01] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 14:36:36,623]\u001b[0m Trial 5 finished with value: 0.9479706950207469 and parameters: {'lambda': 0.011207405714225271, 'alpha': 0.6225985962297583, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.016, 'max_depth': 20, 'min_child_weight': 186}. Best is trial 4 with value: 0.9573392116182573.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:36:36] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 14:38:29,435]\u001b[0m Trial 6 finished with value: 0.9347121369294605 and parameters: {'lambda': 0.0051352578586704315, 'alpha': 0.006042793046879364, 'colsample_bytree': 0.9, 'subsample': 0.5, 'learning_rate': 0.008, 'max_depth': 25, 'min_child_weight': 157}. Best is trial 4 with value: 0.9573392116182573.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:38:29] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 14:39:54,357]\u001b[0m Trial 7 finished with value: 0.9252139522821576 and parameters: {'lambda': 0.014205250234180705, 'alpha': 1.0204267513990612, 'colsample_bytree': 0.9, 'subsample': 0.4, 'learning_rate': 0.008, 'max_depth': 20, 'min_child_weight': 264}. Best is trial 4 with value: 0.9573392116182573.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:39:54] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 14:41:18,541]\u001b[0m Trial 8 finished with value: 0.9299144190871369 and parameters: {'lambda': 0.0033197610377063993, 'alpha': 0.016673004087902836, 'colsample_bytree': 0.8, 'subsample': 0.4, 'learning_rate': 0.012, 'max_depth': 37, 'min_child_weight': 232}. Best is trial 4 with value: 0.9573392116182573.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:18] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 14:43:27,453]\u001b[0m Trial 9 finished with value: 0.9355873962655602 and parameters: {'lambda': 0.001738900234829301, 'alpha': 0.005850845267000803, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.008, 'max_depth': 37, 'min_child_weight': 152}. Best is trial 4 with value: 0.9573392116182573.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:43:28] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 14:46:53,630]\u001b[0m Trial 10 finished with value: 0.9605484958506224 and parameters: {'lambda': 0.526992210668216, 'alpha': 6.455982645041117, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 30, 'min_child_weight': 1}. Best is trial 10 with value: 0.9605484958506224.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:46:54] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 14:50:00,320]\u001b[0m Trial 11 finished with value: 0.9605160788381742 and parameters: {'lambda': 0.41835473478675694, 'alpha': 8.41347475150322, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 30, 'min_child_weight': 2}. Best is trial 10 with value: 0.9605484958506224.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:00] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 14:52:56,007]\u001b[0m Trial 12 finished with value: 0.9592842323651453 and parameters: {'lambda': 0.39979135336619315, 'alpha': 9.658802377904474, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 30, 'min_child_weight': 6}. Best is trial 10 with value: 0.9605484958506224.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:56] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 14:54:42,092]\u001b[0m Trial 13 finished with value: 0.9495915456431535 and parameters: {'lambda': 7.997512001934952, 'alpha': 8.443862594846507, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 40, 'min_child_weight': 98}. Best is trial 10 with value: 0.9605484958506224.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:54:42] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 14:58:09,539]\u001b[0m Trial 14 finished with value: 0.9600946576763485 and parameters: {'lambda': 0.3397552480091733, 'alpha': 2.7024025101072793, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 30, 'min_child_weight': 7}. Best is trial 10 with value: 0.9605484958506224.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:58:10] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 14:59:57,517]\u001b[0m Trial 15 finished with value: 0.952638744813278 and parameters: {'lambda': 1.2664185597819777, 'alpha': 2.2328338907834424, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 10, 'min_child_weight': 99}. Best is trial 10 with value: 0.9605484958506224.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:59:57] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 15:01:05,308]\u001b[0m Trial 16 finished with value: 0.9542271784232366 and parameters: {'lambda': 0.10047382246102932, 'alpha': 2.8328965165440954, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 39}. Best is trial 10 with value: 0.9605484958506224.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:01:05] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 15:02:47,112]\u001b[0m Trial 17 finished with value: 0.9530601659751037 and parameters: {'lambda': 0.9057301711130104, 'alpha': 0.0014425180469830538, 'colsample_bytree': 0.6, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 30, 'min_child_weight': 68}. Best is trial 10 with value: 0.9605484958506224.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:02:47] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 15:04:11,691]\u001b[0m Trial 18 finished with value: 0.9416169605809128 and parameters: {'lambda': 0.12373697489712274, 'alpha': 8.45212557933116, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 30, 'min_child_weight': 296}. Best is trial 10 with value: 0.9605484958506224.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:04:11] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 15:05:14,615]\u001b[0m Trial 19 finished with value: 0.9489432053941909 and parameters: {'lambda': 3.602899892371162, 'alpha': 1.1767720073382437, 'colsample_bytree': 0.5, 'subsample': 0.7, 'learning_rate': 0.02, 'max_depth': 40, 'min_child_weight': 122}. Best is trial 10 with value: 0.9605484958506224.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:05:14] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 15:07:15,199]\u001b[0m Trial 20 finished with value: 0.960224325726141 and parameters: {'lambda': 0.659126824912145, 'alpha': 0.31279700373735314, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 10, 'min_child_weight': 2}. Best is trial 10 with value: 0.9605484958506224.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:07:15] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 15:09:04,085]\u001b[0m Trial 21 finished with value: 0.960191908713693 and parameters: {'lambda': 0.667349881664988, 'alpha': 0.17686275962655978, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 10, 'min_child_weight': 2}. Best is trial 10 with value: 0.9605484958506224.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:09:04] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 15:10:35,146]\u001b[0m Trial 22 finished with value: 0.9567557053941909 and parameters: {'lambda': 2.309606863697893, 'alpha': 4.41203413792645, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 10, 'min_child_weight': 33}. Best is trial 10 with value: 0.9605484958506224.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:10:35] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 15:11:46,413]\u001b[0m Trial 23 finished with value: 0.9549403526970954 and parameters: {'lambda': 0.24196685992328706, 'alpha': 1.4419444774111132, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 28}. Best is trial 10 with value: 0.9605484958506224.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:11:46] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 15:13:23,081]\u001b[0m Trial 24 finished with value: 0.9528656639004149 and parameters: {'lambda': 0.6395697263861618, 'alpha': 0.48638920122124296, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 10, 'min_child_weight': 69}. Best is trial 10 with value: 0.9605484958506224.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:13:23] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 15:15:13,891]\u001b[0m Trial 25 finished with value: 0.9576309647302904 and parameters: {'lambda': 1.2979984542590128, 'alpha': 4.805560852033028, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 30, 'min_child_weight': 24}. Best is trial 10 with value: 0.9605484958506224.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:15:14] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 15:16:29,648]\u001b[0m Trial 26 finished with value: 0.9478086099585062 and parameters: {'lambda': 0.20488376182406468, 'alpha': 4.209782409685503, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 30, 'min_child_weight': 126}. Best is trial 10 with value: 0.9605484958506224.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:16:29] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 15:18:03,453]\u001b[0m Trial 27 finished with value: 0.9526063278008299 and parameters: {'lambda': 0.5331908448512528, 'alpha': 0.8194288066727621, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 10, 'min_child_weight': 56}. Best is trial 10 with value: 0.9605484958506224.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:18:03] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 15:20:57,530]\u001b[0m Trial 28 finished with value: 0.9585386410788381 and parameters: {'lambda': 0.8477834167718901, 'alpha': 1.5504140886534383, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.012, 'max_depth': 30, 'min_child_weight': 18}. Best is trial 10 with value: 0.9605484958506224.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:20:57] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 15:22:22,685]\u001b[0m Trial 29 finished with value: 0.9457663381742739 and parameters: {'lambda': 0.1653243665254985, 'alpha': 0.30303675681969683, 'colsample_bytree': 0.5, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 25, 'min_child_weight': 81}. Best is trial 10 with value: 0.9605484958506224.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b29d07ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_alpha</th>\n",
       "      <th>params_colsample_bytree</th>\n",
       "      <th>params_lambda</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_min_child_weight</th>\n",
       "      <th>params_subsample</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.948749</td>\n",
       "      <td>2023-04-20 14:22:03.343008</td>\n",
       "      <td>2023-04-20 14:25:16.638427</td>\n",
       "      <td>0 days 00:03:13.295419</td>\n",
       "      <td>0.050471</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005431</td>\n",
       "      <td>0.012</td>\n",
       "      <td>25</td>\n",
       "      <td>93</td>\n",
       "      <td>0.7</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.937338</td>\n",
       "      <td>2023-04-20 14:25:16.651269</td>\n",
       "      <td>2023-04-20 14:26:33.643578</td>\n",
       "      <td>0 days 00:01:16.992309</td>\n",
       "      <td>0.196233</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.035834</td>\n",
       "      <td>0.016</td>\n",
       "      <td>15</td>\n",
       "      <td>166</td>\n",
       "      <td>0.4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.945507</td>\n",
       "      <td>2023-04-20 14:26:33.645591</td>\n",
       "      <td>2023-04-20 14:28:46.274849</td>\n",
       "      <td>0 days 00:02:12.629258</td>\n",
       "      <td>0.042281</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.010014</td>\n",
       "      <td>0.012</td>\n",
       "      <td>37</td>\n",
       "      <td>200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.955654</td>\n",
       "      <td>2023-04-20 14:28:46.276662</td>\n",
       "      <td>2023-04-20 14:31:58.251962</td>\n",
       "      <td>0 days 00:03:11.975300</td>\n",
       "      <td>0.013738</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.080074</td>\n",
       "      <td>0.016</td>\n",
       "      <td>15</td>\n",
       "      <td>58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.957339</td>\n",
       "      <td>2023-04-20 14:31:58.254516</td>\n",
       "      <td>2023-04-20 14:35:01.339115</td>\n",
       "      <td>0 days 00:03:03.084599</td>\n",
       "      <td>0.360358</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.326977</td>\n",
       "      <td>0.016</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.947971</td>\n",
       "      <td>2023-04-20 14:35:01.341270</td>\n",
       "      <td>2023-04-20 14:36:36.622811</td>\n",
       "      <td>0 days 00:01:35.281541</td>\n",
       "      <td>0.622599</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.011207</td>\n",
       "      <td>0.016</td>\n",
       "      <td>20</td>\n",
       "      <td>186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.934712</td>\n",
       "      <td>2023-04-20 14:36:36.625353</td>\n",
       "      <td>2023-04-20 14:38:29.434250</td>\n",
       "      <td>0 days 00:01:52.808897</td>\n",
       "      <td>0.006043</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>0.008</td>\n",
       "      <td>25</td>\n",
       "      <td>157</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.925214</td>\n",
       "      <td>2023-04-20 14:38:29.436953</td>\n",
       "      <td>2023-04-20 14:39:54.356325</td>\n",
       "      <td>0 days 00:01:24.919372</td>\n",
       "      <td>1.020427</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.014205</td>\n",
       "      <td>0.008</td>\n",
       "      <td>20</td>\n",
       "      <td>264</td>\n",
       "      <td>0.4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.929914</td>\n",
       "      <td>2023-04-20 14:39:54.359036</td>\n",
       "      <td>2023-04-20 14:41:18.540580</td>\n",
       "      <td>0 days 00:01:24.181544</td>\n",
       "      <td>0.016673</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>0.012</td>\n",
       "      <td>37</td>\n",
       "      <td>232</td>\n",
       "      <td>0.4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.935587</td>\n",
       "      <td>2023-04-20 14:41:18.542402</td>\n",
       "      <td>2023-04-20 14:43:27.452631</td>\n",
       "      <td>0 days 00:02:08.910229</td>\n",
       "      <td>0.005851</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.008</td>\n",
       "      <td>37</td>\n",
       "      <td>152</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.960548</td>\n",
       "      <td>2023-04-20 14:43:27.454474</td>\n",
       "      <td>2023-04-20 14:46:53.630101</td>\n",
       "      <td>0 days 00:03:26.175627</td>\n",
       "      <td>6.455983</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.526992</td>\n",
       "      <td>0.020</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.960516</td>\n",
       "      <td>2023-04-20 14:46:53.631838</td>\n",
       "      <td>2023-04-20 14:50:00.317275</td>\n",
       "      <td>0 days 00:03:06.685437</td>\n",
       "      <td>8.413475</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.418355</td>\n",
       "      <td>0.020</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.959284</td>\n",
       "      <td>2023-04-20 14:50:00.321649</td>\n",
       "      <td>2023-04-20 14:52:56.004078</td>\n",
       "      <td>0 days 00:02:55.682429</td>\n",
       "      <td>9.658802</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.399791</td>\n",
       "      <td>0.020</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.949592</td>\n",
       "      <td>2023-04-20 14:52:56.020303</td>\n",
       "      <td>2023-04-20 14:54:42.092072</td>\n",
       "      <td>0 days 00:01:46.071769</td>\n",
       "      <td>8.443863</td>\n",
       "      <td>0.7</td>\n",
       "      <td>7.997512</td>\n",
       "      <td>0.020</td>\n",
       "      <td>40</td>\n",
       "      <td>98</td>\n",
       "      <td>0.6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.960095</td>\n",
       "      <td>2023-04-20 14:54:42.095484</td>\n",
       "      <td>2023-04-20 14:58:09.538214</td>\n",
       "      <td>0 days 00:03:27.442730</td>\n",
       "      <td>2.702403</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.339755</td>\n",
       "      <td>0.020</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.952639</td>\n",
       "      <td>2023-04-20 14:58:09.542959</td>\n",
       "      <td>2023-04-20 14:59:57.517274</td>\n",
       "      <td>0 days 00:01:47.974315</td>\n",
       "      <td>2.232834</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.266419</td>\n",
       "      <td>0.020</td>\n",
       "      <td>10</td>\n",
       "      <td>99</td>\n",
       "      <td>0.8</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.954227</td>\n",
       "      <td>2023-04-20 14:59:57.519747</td>\n",
       "      <td>2023-04-20 15:01:05.307593</td>\n",
       "      <td>0 days 00:01:07.787846</td>\n",
       "      <td>2.832897</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.100474</td>\n",
       "      <td>0.020</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>0.6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.953060</td>\n",
       "      <td>2023-04-20 15:01:05.310070</td>\n",
       "      <td>2023-04-20 15:02:47.111860</td>\n",
       "      <td>0 days 00:01:41.801790</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.905730</td>\n",
       "      <td>0.020</td>\n",
       "      <td>30</td>\n",
       "      <td>68</td>\n",
       "      <td>0.6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.941617</td>\n",
       "      <td>2023-04-20 15:02:47.114689</td>\n",
       "      <td>2023-04-20 15:04:11.691047</td>\n",
       "      <td>0 days 00:01:24.576358</td>\n",
       "      <td>8.452126</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.123737</td>\n",
       "      <td>0.020</td>\n",
       "      <td>30</td>\n",
       "      <td>296</td>\n",
       "      <td>0.8</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.948943</td>\n",
       "      <td>2023-04-20 15:04:11.692694</td>\n",
       "      <td>2023-04-20 15:05:14.614955</td>\n",
       "      <td>0 days 00:01:02.922261</td>\n",
       "      <td>1.176772</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.602900</td>\n",
       "      <td>0.020</td>\n",
       "      <td>40</td>\n",
       "      <td>122</td>\n",
       "      <td>0.7</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.960224</td>\n",
       "      <td>2023-04-20 15:05:14.619351</td>\n",
       "      <td>2023-04-20 15:07:15.199044</td>\n",
       "      <td>0 days 00:02:00.579693</td>\n",
       "      <td>0.312797</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.659127</td>\n",
       "      <td>0.020</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.960192</td>\n",
       "      <td>2023-04-20 15:07:15.200603</td>\n",
       "      <td>2023-04-20 15:09:04.084078</td>\n",
       "      <td>0 days 00:01:48.883475</td>\n",
       "      <td>0.176863</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.667350</td>\n",
       "      <td>0.020</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.956756</td>\n",
       "      <td>2023-04-20 15:09:04.086788</td>\n",
       "      <td>2023-04-20 15:10:35.145393</td>\n",
       "      <td>0 days 00:01:31.058605</td>\n",
       "      <td>4.412034</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.309607</td>\n",
       "      <td>0.020</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "      <td>0.6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.954940</td>\n",
       "      <td>2023-04-20 15:10:35.147061</td>\n",
       "      <td>2023-04-20 15:11:46.413002</td>\n",
       "      <td>0 days 00:01:11.265941</td>\n",
       "      <td>1.441944</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.241967</td>\n",
       "      <td>0.020</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>0.6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.952866</td>\n",
       "      <td>2023-04-20 15:11:46.414812</td>\n",
       "      <td>2023-04-20 15:13:23.080797</td>\n",
       "      <td>0 days 00:01:36.665985</td>\n",
       "      <td>0.486389</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.639570</td>\n",
       "      <td>0.020</td>\n",
       "      <td>10</td>\n",
       "      <td>69</td>\n",
       "      <td>0.6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.957631</td>\n",
       "      <td>2023-04-20 15:13:23.082943</td>\n",
       "      <td>2023-04-20 15:15:13.890945</td>\n",
       "      <td>0 days 00:01:50.808002</td>\n",
       "      <td>4.805561</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.297998</td>\n",
       "      <td>0.020</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>0.6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.947809</td>\n",
       "      <td>2023-04-20 15:15:13.892533</td>\n",
       "      <td>2023-04-20 15:16:29.647957</td>\n",
       "      <td>0 days 00:01:15.755424</td>\n",
       "      <td>4.209782</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.204884</td>\n",
       "      <td>0.020</td>\n",
       "      <td>30</td>\n",
       "      <td>126</td>\n",
       "      <td>0.6</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.952606</td>\n",
       "      <td>2023-04-20 15:16:29.651865</td>\n",
       "      <td>2023-04-20 15:18:03.453248</td>\n",
       "      <td>0 days 00:01:33.801383</td>\n",
       "      <td>0.819429</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.533191</td>\n",
       "      <td>0.008</td>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "      <td>0.7</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.958539</td>\n",
       "      <td>2023-04-20 15:18:03.454820</td>\n",
       "      <td>2023-04-20 15:20:57.530301</td>\n",
       "      <td>0 days 00:02:54.075481</td>\n",
       "      <td>1.550414</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.847783</td>\n",
       "      <td>0.012</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>0.8</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.945766</td>\n",
       "      <td>2023-04-20 15:20:57.534548</td>\n",
       "      <td>2023-04-20 15:22:22.684606</td>\n",
       "      <td>0 days 00:01:25.150058</td>\n",
       "      <td>0.303037</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.165324</td>\n",
       "      <td>0.012</td>\n",
       "      <td>25</td>\n",
       "      <td>81</td>\n",
       "      <td>0.5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value             datetime_start          datetime_complete  \\\n",
       "0        0  0.948749 2023-04-20 14:22:03.343008 2023-04-20 14:25:16.638427   \n",
       "1        1  0.937338 2023-04-20 14:25:16.651269 2023-04-20 14:26:33.643578   \n",
       "2        2  0.945507 2023-04-20 14:26:33.645591 2023-04-20 14:28:46.274849   \n",
       "3        3  0.955654 2023-04-20 14:28:46.276662 2023-04-20 14:31:58.251962   \n",
       "4        4  0.957339 2023-04-20 14:31:58.254516 2023-04-20 14:35:01.339115   \n",
       "5        5  0.947971 2023-04-20 14:35:01.341270 2023-04-20 14:36:36.622811   \n",
       "6        6  0.934712 2023-04-20 14:36:36.625353 2023-04-20 14:38:29.434250   \n",
       "7        7  0.925214 2023-04-20 14:38:29.436953 2023-04-20 14:39:54.356325   \n",
       "8        8  0.929914 2023-04-20 14:39:54.359036 2023-04-20 14:41:18.540580   \n",
       "9        9  0.935587 2023-04-20 14:41:18.542402 2023-04-20 14:43:27.452631   \n",
       "10      10  0.960548 2023-04-20 14:43:27.454474 2023-04-20 14:46:53.630101   \n",
       "11      11  0.960516 2023-04-20 14:46:53.631838 2023-04-20 14:50:00.317275   \n",
       "12      12  0.959284 2023-04-20 14:50:00.321649 2023-04-20 14:52:56.004078   \n",
       "13      13  0.949592 2023-04-20 14:52:56.020303 2023-04-20 14:54:42.092072   \n",
       "14      14  0.960095 2023-04-20 14:54:42.095484 2023-04-20 14:58:09.538214   \n",
       "15      15  0.952639 2023-04-20 14:58:09.542959 2023-04-20 14:59:57.517274   \n",
       "16      16  0.954227 2023-04-20 14:59:57.519747 2023-04-20 15:01:05.307593   \n",
       "17      17  0.953060 2023-04-20 15:01:05.310070 2023-04-20 15:02:47.111860   \n",
       "18      18  0.941617 2023-04-20 15:02:47.114689 2023-04-20 15:04:11.691047   \n",
       "19      19  0.948943 2023-04-20 15:04:11.692694 2023-04-20 15:05:14.614955   \n",
       "20      20  0.960224 2023-04-20 15:05:14.619351 2023-04-20 15:07:15.199044   \n",
       "21      21  0.960192 2023-04-20 15:07:15.200603 2023-04-20 15:09:04.084078   \n",
       "22      22  0.956756 2023-04-20 15:09:04.086788 2023-04-20 15:10:35.145393   \n",
       "23      23  0.954940 2023-04-20 15:10:35.147061 2023-04-20 15:11:46.413002   \n",
       "24      24  0.952866 2023-04-20 15:11:46.414812 2023-04-20 15:13:23.080797   \n",
       "25      25  0.957631 2023-04-20 15:13:23.082943 2023-04-20 15:15:13.890945   \n",
       "26      26  0.947809 2023-04-20 15:15:13.892533 2023-04-20 15:16:29.647957   \n",
       "27      27  0.952606 2023-04-20 15:16:29.651865 2023-04-20 15:18:03.453248   \n",
       "28      28  0.958539 2023-04-20 15:18:03.454820 2023-04-20 15:20:57.530301   \n",
       "29      29  0.945766 2023-04-20 15:20:57.534548 2023-04-20 15:22:22.684606   \n",
       "\n",
       "                 duration  params_alpha  params_colsample_bytree  \\\n",
       "0  0 days 00:03:13.295419      0.050471                      0.5   \n",
       "1  0 days 00:01:16.992309      0.196233                      0.9   \n",
       "2  0 days 00:02:12.629258      0.042281                      0.9   \n",
       "3  0 days 00:03:11.975300      0.013738                      0.9   \n",
       "4  0 days 00:03:03.084599      0.360358                      0.8   \n",
       "5  0 days 00:01:35.281541      0.622599                      0.6   \n",
       "6  0 days 00:01:52.808897      0.006043                      0.9   \n",
       "7  0 days 00:01:24.919372      1.020427                      0.9   \n",
       "8  0 days 00:01:24.181544      0.016673                      0.8   \n",
       "9  0 days 00:02:08.910229      0.005851                      1.0   \n",
       "10 0 days 00:03:26.175627      6.455983                      0.7   \n",
       "11 0 days 00:03:06.685437      8.413475                      0.7   \n",
       "12 0 days 00:02:55.682429      9.658802                      0.7   \n",
       "13 0 days 00:01:46.071769      8.443863                      0.7   \n",
       "14 0 days 00:03:27.442730      2.702403                      0.7   \n",
       "15 0 days 00:01:47.974315      2.232834                      0.7   \n",
       "16 0 days 00:01:07.787846      2.832897                      0.7   \n",
       "17 0 days 00:01:41.801790      0.001443                      0.6   \n",
       "18 0 days 00:01:24.576358      8.452126                      1.0   \n",
       "19 0 days 00:01:02.922261      1.176772                      0.5   \n",
       "20 0 days 00:02:00.579693      0.312797                      0.7   \n",
       "21 0 days 00:01:48.883475      0.176863                      0.7   \n",
       "22 0 days 00:01:31.058605      4.412034                      0.7   \n",
       "23 0 days 00:01:11.265941      1.441944                      0.7   \n",
       "24 0 days 00:01:36.665985      0.486389                      0.7   \n",
       "25 0 days 00:01:50.808002      4.805561                      0.7   \n",
       "26 0 days 00:01:15.755424      4.209782                      0.7   \n",
       "27 0 days 00:01:33.801383      0.819429                      0.6   \n",
       "28 0 days 00:02:54.075481      1.550414                      0.8   \n",
       "29 0 days 00:01:25.150058      0.303037                      0.5   \n",
       "\n",
       "    params_lambda  params_learning_rate  params_max_depth  \\\n",
       "0        0.005431                 0.012                25   \n",
       "1        0.035834                 0.016                15   \n",
       "2        2.010014                 0.012                37   \n",
       "3        0.080074                 0.016                15   \n",
       "4        0.326977                 0.016                30   \n",
       "5        0.011207                 0.016                20   \n",
       "6        0.005135                 0.008                25   \n",
       "7        0.014205                 0.008                20   \n",
       "8        0.003320                 0.012                37   \n",
       "9        0.001739                 0.008                37   \n",
       "10       0.526992                 0.020                30   \n",
       "11       0.418355                 0.020                30   \n",
       "12       0.399791                 0.020                30   \n",
       "13       7.997512                 0.020                40   \n",
       "14       0.339755                 0.020                30   \n",
       "15       1.266419                 0.020                10   \n",
       "16       0.100474                 0.020                 5   \n",
       "17       0.905730                 0.020                30   \n",
       "18       0.123737                 0.020                30   \n",
       "19       3.602900                 0.020                40   \n",
       "20       0.659127                 0.020                10   \n",
       "21       0.667350                 0.020                10   \n",
       "22       2.309607                 0.020                10   \n",
       "23       0.241967                 0.020                 5   \n",
       "24       0.639570                 0.020                10   \n",
       "25       1.297998                 0.020                30   \n",
       "26       0.204884                 0.020                30   \n",
       "27       0.533191                 0.008                10   \n",
       "28       0.847783                 0.012                30   \n",
       "29       0.165324                 0.012                25   \n",
       "\n",
       "    params_min_child_weight  params_subsample     state  \n",
       "0                        93               0.7  COMPLETE  \n",
       "1                       166               0.4  COMPLETE  \n",
       "2                       200               1.0  COMPLETE  \n",
       "3                        58               1.0  COMPLETE  \n",
       "4                        40               1.0  COMPLETE  \n",
       "5                       186               1.0  COMPLETE  \n",
       "6                       157               0.5  COMPLETE  \n",
       "7                       264               0.4  COMPLETE  \n",
       "8                       232               0.4  COMPLETE  \n",
       "9                       152               0.5  COMPLETE  \n",
       "10                        1               0.6  COMPLETE  \n",
       "11                        2               0.6  COMPLETE  \n",
       "12                        6               0.6  COMPLETE  \n",
       "13                       98               0.6  COMPLETE  \n",
       "14                        7               0.6  COMPLETE  \n",
       "15                       99               0.8  COMPLETE  \n",
       "16                       39               0.6  COMPLETE  \n",
       "17                       68               0.6  COMPLETE  \n",
       "18                      296               0.8  COMPLETE  \n",
       "19                      122               0.7  COMPLETE  \n",
       "20                        2               0.6  COMPLETE  \n",
       "21                        2               0.6  COMPLETE  \n",
       "22                       33               0.6  COMPLETE  \n",
       "23                       28               0.6  COMPLETE  \n",
       "24                       69               0.6  COMPLETE  \n",
       "25                       24               0.6  COMPLETE  \n",
       "26                      126               0.6  COMPLETE  \n",
       "27                       56               0.7  COMPLETE  \n",
       "28                       18               0.8  COMPLETE  \n",
       "29                       81               0.5  COMPLETE  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7be8e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 30\n",
      "Best trial: {'lambda': 0.526992210668216, 'alpha': 6.455982645041117, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 30, 'min_child_weight': 1}\n",
      "Best MSE: 0.9605484958506224\n"
     ]
    }
   ],
   "source": [
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)\n",
    "print('Best MSE:', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a31c9745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:32:49] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy on validation set is 94.82984293193716%\n"
     ]
    }
   ],
   "source": [
    "final_model = xgb.XGBClassifier(**study.best_trial.params)\n",
    "final_model.fit(X_train, y_train)\n",
    "y_val_pred = final_model.predict(X_val)\n",
    "print(\"Accuracy on validation set is {}%\".format(accuracy_score(y_val, y_val_pred)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
